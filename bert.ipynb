{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e9bc28-b96b-4966-b884-d72c55613dc4",
   "metadata": {},
   "source": [
    "# Fine-Tuning BERT for Classification\n",
    "In this notebook, I fine-tune an encoder-only model for classification. I'm doing this so that I can show the differences in the classic fine-tunine pipeline compared to the QLoRA pipeline. The QLoRA pipeline has numerous differences. This classic pipeline works very well, but it's main disadvantage is that it can require a lot of GPU VRAM. I am currently doing this project using an RTX 4090 GPU (laptop edition), which has 16 GB of VRAM. This amount of VRAM is enough for bert-base-uncased, which has about 110M parameters, but it is not enough VRAM for bert-large-uncased, which has about 336M parameters. Therefore, if I want to load a larger model into the GPU VRAM for fine-tuning or inferencing, I would not be able to load it in the traditional way. Please check out the qlora notebook for more detail on loading larger models without needing as much VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b93b16d-a7dc-4a7a-8f74-b6ff7cf3cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import wandb \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    BertForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557f3db-06e9-4980-8a09-b47b4cc797ce",
   "metadata": {},
   "source": [
    "### Initializing Weights & Biases.\n",
    "\n",
    "In order to track my runs, I am using Weights & Biases. There are other tools that can also be useful for this, such as TensorBoard or Aim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260235bf-014e-4602-89a5-9b708ae67901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukemonington3\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/notebooks/driver-intent/wandb/run-20231001_213312-veilc20u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lukemonington3/driver-intent-classification/runs/veilc20u' target=\"_blank\">bert-run</a></strong> to <a href='https://wandb.ai/lukemonington3/driver-intent-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lukemonington3/driver-intent-classification' target=\"_blank\">https://wandb.ai/lukemonington3/driver-intent-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lukemonington3/driver-intent-classification/runs/veilc20u' target=\"_blank\">https://wandb.ai/lukemonington3/driver-intent-classification/runs/veilc20u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/lukemonington3/driver-intent-classification/runs/veilc20u?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f249698df60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"driver-intent-classification\", name=\"bert-run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47c3a1-6e2c-432d-9079-fa8aeebae22c",
   "metadata": {},
   "source": [
    "# Loading the Model and Tokenizer\n",
    "Transfer Learning is a technique where a model trained on one task is adapted for a second related task. This method is especially beneficial when there is only a small amount of data for available for a specific task. By utilizing a model pre-trained on a larger dataset, such as BERT, it is possible to leverage pre-learned features and achieve better performance with less data and computational resources.\n",
    "\n",
    "In this project, I am employing transfer learning by using a pre-trained tokenizer and BERT model. BERT has been pre-trained on a massive corpus of text and has learned a rich representation of language. I will fine-tune BERT on the dataset that I created for driver intent classification in order to achieve higher performance with less effort and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7713b1bd-1e9c-4f1f-a487-0ff9050b6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "path_to_retrieve = \"../tokenized_dataset\"\n",
    "dataset_dict = load_from_disk(path_to_retrieve)\n",
    "\n",
    "model_name = 'bert-base-uncased' \n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c487ac10-a5b6-483e-beaa-e99b17c3207d",
   "metadata": {},
   "source": [
    "# Trainable Parameters\n",
    "Since I am not using any parameter efficient techniques, I am training the full 100% of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7bdee0-56dd-49d0-807a-f3d99a8c9e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 109486085 || all params: 109486085 || trainable%: 100.00\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e922d-9f0e-4aee-837a-99ed7aa3af49",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for Multi-class Classification\n",
    "\n",
    "In multi-class classification tasks, it is crucial to choose the right metric to evaluate the performance of the model. Several metrics could be considered, each with its own advantages and disadvantages depending on the specific task and the dataset. Below are some of the commonly used metrics for multi-class classification:\n",
    "\n",
    "1. **Accuracy**: \n",
    "    - Accuracy is the ratio of correctly predicted instances to the total instances. It's a straightforward metric to understand and works well when the classes are balanced and the cost of misclassification is the same across different classes.\n",
    "    \\[ \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}} \\]\n",
    "\n",
    "2. **Precision, Recall, and F1-Score**:\n",
    "    - Precision is the ratio of correctly predicted positive observations to the total predicted positives. \n",
    "    - Recall (Sensitivity) - the ratio of correctly predicted positive observations to the all observations in actual class.\n",
    "    - The F1 Score is the weighted average of Precision and Recall. It tries to find the balance between precision and recall.\n",
    "    - These metrics are useful when the costs of false positives and false negatives are significantly different.\n",
    "\n",
    "3. **Confusion Matrix**:\n",
    "    - A confusion matrix is a table that is often used to describe the performance of a classification model on a set of data for which the true values are known. It gives a more detailed view of what kind of errors the model is making.\n",
    "\n",
    "4. **Macro and Micro Averaging**:\n",
    "    - In a multi-class classification setup, precision, recall, and F1-score can be calculated on a per-class basis, but summarizing them into a single figure requires either macro-averaging (calculate metric for each class independently and then average) or micro-averaging (aggregate the contributions of all classes to compute the average metric).\n",
    "\n",
    "5. **Log-Loss**:\n",
    "    - Log Loss is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks. It's a measure of error and unlike accuracy, the log loss metric is more sensitive to the confidence of the predictions.\n",
    "\n",
    "In the context of this project, I am tackling a driver intent classification problem where the task is to predict the driver's intent among five classes: lowering the driver side window, lowering the passenger side window, turning on the A/C, and others. Given that I created a balanced dataset (each class is equally represented), using **accuracy** as my metric is a sensible choice. It provides a clear and understandable measure of our model's performance across all classes, and the cost of misclassification is assumed to be the same across different classes. Further, since I have balanced classes, I do not need to worry about the model biasing towards the majority class, which can sometimes happen in imbalanced settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b69374b-89c4-4c70-9cc6-1f8f732c15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    logits, labels = p.predictions, p.label_ids\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    wandb.log({\"accuracy\": acc})  \n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f232069e-3986-4882-9483-7158ef26b87d",
   "metadata": {},
   "source": [
    "# Callbacks and Their Utility\n",
    "\n",
    "Callbacks in machine learning are a type of function that can be applied at certain stages of training processes, allowing more control during training, monitoring, or even altering the behavior of the model during training. They can help to get insights into the internal states of the model during training, perform actions, log information, or even stop training early if a certain condition is met.\n",
    "\n",
    "In this case, I utilized a callback from the Transformers library called `EarlyStoppingCallback`. This particular callback helps to stop the training process once the model ceases to improve, saving computational resources and time. It's particularly beneficial in preventing overfitting, where the model starts learning the noise in the training data rather than the actual underlying pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1fcde9-e1f5-4d86-a813-9a0062c33a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ab6c1-4b22-43d3-903c-e983186e6094",
   "metadata": {},
   "source": [
    "# Fine-Tuning for Multi-Class Classification\n",
    "\n",
    "Fine-tuning involves making minimal adjustments to a pre-trained model to adapt it to new, but related data. In the context of multi-class classification for driver intent recognition, fine-tuning a pre-trained model like BERT can provide a strong foundation of language understanding while adapting to the specifics of the task at hand. This not only saves computational resources compared to training a model from scratch but often achieves higher performance.\n",
    "\n",
    "* `per_device_train_batch_size` and `per_device_eval_batch_size`: These parameters control the batch size during training and evaluation, respectively, which affects the memory usage and potentially the performance of the model. \n",
    "* `num_train_epochs`: Specifies the number of times the entire training dataset will be passed through the model.\n",
    "* `evaluation_strategy`, `save_steps`, and `save_total_limit`: These parameters control the evaluation and saving of the model during training, enabling efficient monitoring and ensuring that only a specified number of model checkpoints are saved to conserve storage space.\n",
    "* `load_best_model_at_end`: Ensures that the best model is loaded at the end of training for further use or analysis.\n",
    "* `learning_rate`: Controls the step size at each iteration while moving towards a minimum of the loss function, a crucial parameter for the convergence and the performance of the trained model.\n",
    "* `metric_for_best_model`: Specifies the metric to use for model evaluation, in this case, accuracy, which is a suitable choice given the balanced nature of the dataset.\n",
    "\n",
    "The Trainer class from the Transformers library encapsulates the training process, providing a simple and efficient way to train and evaluate the model on the specified datasets. Additionally, the callbacks parameter allows the inclusion of previously discussed EarlyStoppingCallback, optimizing the training process by stopping it once the model ceases to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9fedc1-7b52-4c25-b556-46359e3ea2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir='../bert-models',\n",
    "    num_train_epochs=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=4,\n",
    "    remove_unused_columns=False,\n",
    "    run_name='run_name',\n",
    "    logging_dir='/logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='wandb', \n",
    "    learning_rate=3e-5,\n",
    "    metric_for_best_model=\"accuracy\", \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbc3633f-985f-45ff-afa5-2cabdb646a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 100/1000 00:54 < 08:23, 1.79 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.568400</td>\n",
       "      <td>1.374174</td>\n",
       "      <td>0.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.312600</td>\n",
       "      <td>1.074465</td>\n",
       "      <td>0.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.962200</td>\n",
       "      <td>0.766735</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.733600</td>\n",
       "      <td>0.463244</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>0.277607</td>\n",
       "      <td>0.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.272900</td>\n",
       "      <td>0.163378</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.085314</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.037101</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.5612843580543995, metrics={'train_runtime': 55.4647, 'train_samples_per_second': 144.236, 'train_steps_per_second': 18.03, 'total_flos': 210494513971200.0, 'train_loss': 0.5612843580543995, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa1fc0-2a67-4cb4-8850-6b6449fe9d10",
   "metadata": {},
   "source": [
    "# Saving the Model\n",
    "Once the model finishes training, the berst model is loaded. I save this model separately so that I can use it later in the Gradio application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2956abfe-9044-4570-82c3-6e9d107338c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../bert-models/best_model\"\n",
    "model.save_pretrained(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
