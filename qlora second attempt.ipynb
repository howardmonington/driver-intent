{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca8a8e7-082f-4ad6-8fa9-5659c885c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from datasets import DatasetDict, Dataset, load_from_disk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BitsAndBytesConfig\n",
    "from accelerate import Accelerator\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, TaskType, get_peft_model\n",
    "from transformers import TrainingArguments, AutoConfig, \\\n",
    "    AutoModelForSequenceClassification, AutoTokenizer, BitsAndBytesConfig, DataCollatorWithPadding\n",
    "from peft import (\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897177b6-1d67-4f28-a549-48bb15d54e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_retrieve = \"../tokenized_dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604af393-7fa0-4411-82bd-94d227dfb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = load_from_disk(path_to_retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf30437-e107-430f-b08f-6e32057807a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f3b5117-f8bf-433e-82ce-a54978711475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2775642-aa2a-456d-8c07-a8a232d4ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"bert-large-uncased\"\n",
    "num_labels=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e405338-30a5-41da-93dd-2b72e09b07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0907f0ab-ede0-49b7-a96a-cc0bef9f3fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, quantization_config=bnb_config,\n",
    "                                                           config=AutoConfig.from_pretrained(model_id,\n",
    "                                                                                             trust_remote_code=True,\n",
    "                                                                                             num_labels=num_labels),\n",
    "                                                           trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17cb4164-06bd-4d8d-96c1-87202870eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 183627781 || trainable%: 0.00\n"
     ]
    }
   ],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26d49a-ddb6-4e31-a7cf-923db7b760ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778880ee-d58b-4be5-90ee-151fae938b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5b319-1284-47ca-b6c0-26ad4288bdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a629010-de9f-4bdd-9484-fa8776efcf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8888c0-9374-45cc-a9a2-aecc04f545bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    logits, labels = p.predictions, p.label_ids\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45bf974-0a6f-48c7-add5-4a96d34f6e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir='/results',\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    run_name='run_name',\n",
    "    logging_dir='/logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa6d76e2-1681-440d-b2aa-38569d3a1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"test\"],\n",
    "    compute_metrics=compute_metrics, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8349a52d-83c1-4f0e-bf02-7c2763237565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukemonington3\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09344c65b2224bdc86fe3a36354ed8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112344188909952, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/notebooks/driver-intent/wandb/run-20230928_000212-q5tdh7nf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lukemonington3/huggingface/runs/q5tdh7nf' target=\"_blank\">run_name</a></strong> to <a href='https://wandb.ai/lukemonington3/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lukemonington3/huggingface' target=\"_blank\">https://wandb.ai/lukemonington3/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lukemonington3/huggingface/runs/q5tdh7nf' target=\"_blank\">https://wandb.ai/lukemonington3/huggingface/runs/q5tdh7nf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 11/100 00:01 < 00:18, 4.81 it/s, Epoch 0.10/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1556\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1554\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1930\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1930\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2268\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2269\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2323\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   2324\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2325\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled:\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;66;03m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m     \u001b[38;5;66;03m# config `stage3_gather_16bit_weights_on_model_save` is True\u001b[39;00m\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2817\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   2816\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2817\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2875\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2873\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   2874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2875\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2876\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_safetensors\u001b[49m\n\u001b[1;32m   2877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2880\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1837\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   1830\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1831\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` to a 8-bit converted model you may likely encounter unexepected\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m behaviors. If you want to save 8-bit models, make sure to have `bitsandbytes>0.37.2` installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1833\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1834\u001b[0m     )\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 1837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` on a 4-bit converted model. This is currently not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1839\u001b[0m     )\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1842\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1844\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported"
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb4828a8-0a9e-4d18-92a2-916ed516944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.0.0\n",
      "accelerate==0.23.0\n",
      "aiohttp==3.8.5\n",
      "aiosignal==1.3.1\n",
      "anyio==4.0.0\n",
      "appdirs==1.4.4\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.2.3\n",
      "asttokens==2.4.0\n",
      "async-lru==2.0.4\n",
      "async-timeout==4.0.3\n",
      "attrs==23.1.0\n",
      "Babel==2.12.1\n",
      "backcall==0.2.0\n",
      "beautifulsoup4==4.12.2\n",
      "bitsandbytes==0.41.1\n",
      "bleach==6.0.0\n",
      "blinker==1.4\n",
      "cachetools==5.3.1\n",
      "certifi==2023.7.22\n",
      "cffi==1.15.1\n",
      "charset-normalizer==3.2.0\n",
      "click==8.1.7\n",
      "cmake==3.27.5\n",
      "comm==0.1.4\n",
      "contourpy==1.1.1\n",
      "cryptography==3.4.8\n",
      "cycler==0.11.0\n",
      "datasets==2.14.5\n",
      "dbus-python==1.2.18\n",
      "debugpy==1.8.0\n",
      "decorator==5.1.1\n",
      "deepspeed==0.10.3\n",
      "defusedxml==0.7.1\n",
      "dill==0.3.7\n",
      "distro==1.7.0\n",
      "distro-info==1.1+ubuntu0.1\n",
      "docker-pycreds==0.4.0\n",
      "evaluate==0.4.0\n",
      "exceptiongroup==1.1.3\n",
      "executing==1.2.0\n",
      "fastjsonschema==2.18.0\n",
      "filelock==3.12.4\n",
      "fonttools==4.42.1\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.4.0\n",
      "fsspec==2023.6.0\n",
      "gitdb==4.0.10\n",
      "GitPython==3.1.37\n",
      "glob2==0.7\n",
      "google-auth==2.23.1\n",
      "google-auth-oauthlib==1.0.0\n",
      "grpcio==1.58.0\n",
      "hjson==3.1.0\n",
      "httplib2==0.20.2\n",
      "huggingface-hub==0.17.3\n",
      "idna==3.4\n",
      "importlib-metadata==4.6.4\n",
      "ipykernel==6.25.2\n",
      "ipython==8.15.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==8.1.1\n",
      "isoduration==20.11.0\n",
      "jedi==0.19.0\n",
      "jeepney==0.7.1\n",
      "Jinja2==3.1.2\n",
      "joblib==1.3.2\n",
      "json5==0.9.14\n",
      "jsonpointer==2.4\n",
      "jsonschema==4.19.1\n",
      "jsonschema-specifications==2023.7.1\n",
      "jupyter==1.0.0\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.7.0\n",
      "jupyter-lsp==2.2.0\n",
      "jupyter_client==8.3.1\n",
      "jupyter_core==5.3.2\n",
      "jupyter_server==2.7.3\n",
      "jupyter_server_terminals==0.4.4\n",
      "jupyterlab==4.0.6\n",
      "jupyterlab-pygments==0.2.2\n",
      "jupyterlab-widgets==3.0.9\n",
      "jupyterlab_server==2.25.0\n",
      "keyring==23.5.0\n",
      "kiwisolver==1.4.5\n",
      "launchpadlib==1.10.16\n",
      "lazr.restfulclient==0.14.4\n",
      "lazr.uri==1.0.6\n",
      "lightning-utilities==0.9.0\n",
      "lit==17.0.1\n",
      "Markdown==3.4.4\n",
      "MarkupSafe==2.1.3\n",
      "matplotlib==3.8.0\n",
      "matplotlib-inline==0.1.6\n",
      "mistune==3.0.1\n",
      "more-itertools==8.10.0\n",
      "mpi4py==3.1.4\n",
      "mpmath==1.3.0\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.15\n",
      "nbclient==0.8.0\n",
      "nbconvert==7.8.0\n",
      "nbformat==5.9.2\n",
      "nest-asyncio==1.5.8\n",
      "networkx==3.1\n",
      "ninja==1.11.1\n",
      "nltk==3.8.1\n",
      "notebook==7.0.4\n",
      "notebook_shim==0.2.3\n",
      "numpy==1.26.0\n",
      "nvidia-cublas-cu11==11.10.3.66\n",
      "nvidia-cuda-cupti-cu11==11.7.101\n",
      "nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "nvidia-cuda-runtime-cu11==11.7.99\n",
      "nvidia-cudnn-cu11==8.5.0.96\n",
      "nvidia-cufft-cu11==10.9.0.58\n",
      "nvidia-curand-cu11==10.2.10.91\n",
      "nvidia-cusolver-cu11==11.4.0.1\n",
      "nvidia-cusparse-cu11==11.7.4.91\n",
      "nvidia-nccl-cu11==2.14.3\n",
      "nvidia-nvtx-cu11==11.7.91\n",
      "oauthlib==3.2.0\n",
      "overrides==7.4.0\n",
      "packaging==23.1\n",
      "pandas==2.1.1\n",
      "pandocfilters==1.5.0\n",
      "parso==0.8.3\n",
      "pathtools==0.1.2\n",
      "peft==0.5.0\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==10.0.1\n",
      "platformdirs==3.10.0\n",
      "prometheus-client==0.17.1\n",
      "prompt-toolkit==3.0.39\n",
      "protobuf==4.24.3\n",
      "psutil==5.9.5\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "py-cpuinfo==9.0.0\n",
      "pyarrow==13.0.0\n",
      "pyasn1==0.5.0\n",
      "pyasn1-modules==0.3.0\n",
      "pycparser==2.21\n",
      "pydantic==1.10.13\n",
      "Pygments==2.16.1\n",
      "PyGObject==3.42.1\n",
      "PyJWT==2.3.0\n",
      "pyparsing==2.4.7\n",
      "python-apt==2.4.0+ubuntu2\n",
      "python-dateutil==2.8.2\n",
      "python-json-logger==2.0.7\n",
      "pytorch-lightning==2.0.9\n",
      "pytz==2023.3.post1\n",
      "PyYAML==6.0.1\n",
      "pyzmq==25.1.1\n",
      "qtconsole==5.4.4\n",
      "QtPy==2.4.0\n",
      "referencing==0.30.2\n",
      "regex==2023.8.8\n",
      "requests==2.31.0\n",
      "requests-oauthlib==1.3.1\n",
      "responses==0.18.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rpds-py==0.10.3\n",
      "rsa==4.9\n",
      "safetensors==0.3.3\n",
      "scikit-learn==1.3.1\n",
      "scipy==1.11.2\n",
      "SecretStorage==3.3.1\n",
      "Send2Trash==1.8.2\n",
      "sentencepiece==0.1.99\n",
      "sentry-sdk==1.31.0\n",
      "setproctitle==1.3.2\n",
      "six==1.16.0\n",
      "smmap==5.0.1\n",
      "sniffio==1.3.0\n",
      "soupsieve==2.5\n",
      "stack-data==0.6.2\n",
      "sympy==1.12\n",
      "tensorboard==2.14.0\n",
      "tensorboard-data-server==0.7.1\n",
      "terminado==0.17.1\n",
      "threadpoolctl==3.2.0\n",
      "tinycss2==1.2.1\n",
      "tokenizers==0.13.3\n",
      "tomli==2.0.1\n",
      "torch==2.0.1\n",
      "torchmetrics==1.2.0\n",
      "tornado==6.3.3\n",
      "tqdm==4.66.1\n",
      "traitlets==5.10.1\n",
      "transformers==4.33.3\n",
      "triton==2.0.0\n",
      "typing_extensions==4.8.0\n",
      "tzdata==2023.3\n",
      "unattended-upgrades==0.1\n",
      "uri-template==1.3.0\n",
      "urllib3==2.0.5\n",
      "wadllib==1.3.6\n",
      "wandb==0.15.11\n",
      "wcwidth==0.2.6\n",
      "webcolors==1.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.6.3\n",
      "Werkzeug==2.3.7\n",
      "widgetsnbextension==4.0.9\n",
      "xxhash==3.3.0\n",
      "yarl==1.9.2\n",
      "zipp==1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600cba7-cb75-4740-877f-2da07edf8cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
